{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f836d-d32a-4f0e-b5a9-51b5c2736f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import csv\n",
    "from tqdm import tqdm      \n",
    "\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_community.vectorstores import ( \n",
    "    Chroma,\n",
    "    FAISS,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    JsonOutputParser,\n",
    "    PydanticOutputParser\n",
    ")\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757e237-df57-46cd-94e7-3e1a97b64fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"<Your API key here>\"",
    "\n",
    "os.environ[\"OPENAI_ORGANIZATION\"] = \"<Your organisation here>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcce6a1-78ee-44c1-a26e-0aa25883bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenQ(BaseModel):\n",
    "    \"\"\"Individual QnA pair\"\"\"\n",
    "    question: str= Field(description=\"individual question generated\")\n",
    "    answer: str= Field(description=\"corresponding sub-context\")\n",
    "\n",
    "class GenQList(BaseModel):\n",
    "    \"\"\"List of QnA pairs\"\"\"\n",
    "    data: List[GenQ]\n",
    "\n",
    "class QuestionGeneration:\n",
    "    def __init__(self, dataset, xot):\n",
    "        \"\"\"Initialize the llm and parser\"\"\"\n",
    "        self.dataset = load_dataset(dataset) \n",
    "        self.data_dict_list_qna_pairs = [{\"question\": row[\"question\"], \"answer\": row[\"answer\"]} for row in self.dataset[\"train\"]]\n",
    "        self.prompt = None\n",
    "        self.llm = ChatOpenAI(temperature=0.2)\n",
    "        self.xot = xot\n",
    "        self.output_parser = JsonOutputParser(pydantic_object=GenQList)\n",
    "    \n",
    "    def similarity_prompt(self, context):\n",
    "        \"\"\"Prompt Generation\"\"\"\n",
    "        example_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"answer\"],\n",
    "            template=\"Context:{answer}\\nQuestion: {question}\",\n",
    "        )\n",
    "        \n",
    "        example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "            self.data_dict_list_qna_pairs, #examples,\n",
    "            OpenAIEmbeddings(),  # HuggingFaceEmbeddings(),\n",
    "            FAISS,  # Chroma,\n",
    "            k=10,\n",
    "        )\n",
    "        \n",
    "        return FewShotPromptTemplate(\n",
    "            example_selector=example_selector,\n",
    "            example_prompt=example_prompt,\n",
    "            prefix=\"These are the few examples of questions pertaining to the Indian Constitution, judiciary, legislative, and various socio-political issues in India. \\n<Examples>\",\n",
    "            suffix=\"</Examples>\\n<Provided context>\\n{context}\\n</Provided context>\\n{format_instructions}\\n{instruction}\",\n",
    "            input_variables=[\"context\", \"instruction\"],\n",
    "            partial_variables={\"format_instructions\": self.output_parser.get_format_instructions()}\n",
    "        )\n",
    "    def invoke(self, context, raw_output=False):\n",
    "        self.prompt = self.similarity_prompt(context)\n",
    "        if raw_output:\n",
    "            chain = self.prompt | self.llm\n",
    "        else:\n",
    "            chain = self.prompt  | self.llm |  self.output_parser\n",
    "        response = chain.invoke({\"context\": context, \"instruction\": self.xot})\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928e9f7-fb7e-4a4c-ac46-e6c329e7e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_to_json(data, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            existing_data = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        existing_data = []\n",
    "\n",
    "    existing_data.extend(data)\n",
    "    \n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(existing_data, json_file, indent=2)\n",
    "\n",
    "def add_to_dict(list_of_dicts, doc_id, para_no):\n",
    "    for dictionary in list_of_dicts:\n",
    "        dictionary[\"doc_id\"] = doc_id\n",
    "        dictionary[\"paragraph_no\"] = para_no\n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c229b-5c05-4b65-b6bf-387dffd68638",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"paragraphs_dataset.csv\"\n",
    "\n",
    "with open(csv_file_path, 'r', newline='', encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    paragraphs = [{\"doc_id\": row[\"doc_id\"], \"paragraph_num\": row[\"paragraph_num\"], 'content': row[\"content\"]} for row in reader]\n",
    "\n",
    "start_paragraph = 1680\n",
    "end_paragraph = 2000\n",
    "\n",
    "json_file_path = f\"qna_{start_paragraph}_{end_paragraph}_{datetime.now().strftime('%Y%m%d%H%M%S')}_json.json\"\n",
    "\n",
    "tot = \"Walk me through this context in manageable parts, step by step, summarizing and analysing as we go\"\n",
    "inl = \"Generate the multiple questions from the given context. The generated questions should be similar to question as in examples. The only thing generated should be the questions and corresponding context( from original text) from which the question generated.\"\n",
    "inl = tot+\" and \"+inl\n",
    "\n",
    "total_paragraphs = end_paragraph - start_paragraph\n",
    "\n",
    "progress_bar = tqdm(total=total_paragraphs, desc=\"Processing\")\n",
    "\n",
    "tmp = []\n",
    "qg = QuestionGeneration(\"nisaar/Lawyer_GPT_India\", inl)\n",
    "for index in range(start_paragraph, end_paragraph):\n",
    "    paragraph = paragraphs[index].get(\"content\")\n",
    "    text = \" \".join(paragraph.split())\n",
    "    doc_id = paragraphs[index].get(\"doc_id\")\n",
    "    para_no = paragraphs[index].get(\"paragraph_num\")\n",
    "    response = qg.invoke(context=text)\n",
    "    if isinstance(response, dict):\n",
    "        modified_response = add_to_dict(response.get(\"data\"), doc_id=doc_id, para_no=para_no)\n",
    "        tmp.extend(modified_response) \n",
    "    if (index % 10 == 9) or (index == end_paragraph - 1):\n",
    "        save_to_json(tmp, json_file_path) \n",
    "        tmp = []\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "tqdm._instances.clear()\n",
    "\n",
    "print(f\"List of JSON objects saved to {json_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
